# Работа с пакетом `io` в Go
## Введение
Go является языком программирования, хорошо приспособленным для работы с байтами. Будь у вас списки байт, потоки байт или просто отдельные байты, в Go легко с ними работать. Это примитивы, на которых мы строим наши абстракции и сервисы.


Пакет io является одним из самых фундаментальных во всей стандартной библиотеке. Он предоставляет набор интерфейсов и вспомогательных функций для работы с потоками байтов.


### Что такое пакет io?
- Базовый пакет для работы с потоками данных (ввод/вывод).

#### Основные задачи:

- Чтение данных из источников (файлы, сеть, буферы).
- Запись данных в приемники.
- Создание абстракций для универсальной работы с I/O.

**Важность**: Пакет используется почти во всех программах, работающих с данными.

## Чтение байтов

### Интерфейс `Reader`

Простейшая конструкция для чтения байтов из потока это интерфейс Reader:

``` go
type Reader interface {
    Read(p []byte) (n int, err error)
}
```

**Примеры**: файлы, сетевые соединения, строки.

<!-- 
`Reader` принимает на вход буфер, `p`, как параметр для метода `Read()`, чтобы не нужно было выделять память. Если бы `Read()` возвращал новый слайс, вместо того, чтобы принимать его как аргумент, ридеру пришлось бы выделять память при каждом вызове `Read()`. Это была бы катастрофа для сборщика мусора. -->

<!-- Одна из проблем с интерфейсом `Reader` в том, что с ним идёт набор довольно витиеватых правил. 

Во-первых, он возвращает ошибку `io.EOF` при нормальном ходе дел, просто если поток данных завершился. Это может запутывать новичков. 

Во-вторых, нет гарантии, что ваш буфер будет заполнен целиком. Если вы 
передали 8-байтовый слайс, по факту вы можете прочитать от 0 до 8 байт. Обработка чтения по частям можем быть непростой и легко подвержена ошибкам. К счастью, у нас есть немало вспомогательных функций для решения этих задач. -->

#### Чтение данных из строки
``` go
reader := strings.NewReader("Hello, io package!")
data := make([]byte, 5)
n, err := reader.Read(data) // n = 5, data = "Hello"
```
#### Чтение данных из файла
``` go
file, err := os.Open("data.txt")
if err != nil {
    panic(err)
}
defer file.Close() // Закрываем файл при завершении

// Читаем данные по частям (буфер 256 байт)
buffer := make([]byte, 256)
for {
    n, err := file.Read(buffer)
    if err != nil {
        if err == io.EOF {
            fmt.Println("\nКонец файла.")
            break
        }
        panic(err)
    }
    fmt.Printf("Прочитано %d байт: %q\n", n, buffer[:n])
}
```
#### Чтение данных из сетевого соединения
``` go
// Подключаемся к серверу
conn, err := net.Dial("tcp", "example.com:80")
if err != nil {
    panic(err)
}
defer conn.Close() // Закрываем соединение

// Отправляем HTTP-запрос
_, err = conn.Write([]byte("GET / HTTP/1.1\r\nHost: example.com\r\n\r\n"))
if err != nil {
    panic(err)
}

// Читаем ответ от сервера
response, err := io.ReadAll(conn)
if err != nil {
    panic(err)
}

fmt.Printf("Ответ сервера (%d байт):\n%s\n", len(response), response)
```
### Улучшаем гарантии

<!-- Представим, что у вас есть протокол, который нужно распарсить и вы хотите прочесть 8-байтовое uint64 значение из ридера. В этом случае предпочтительней использовать `io.ReadFull()`, так как вы точно знаете, сколько хотите прочесть: -->

`io.ReadFull()`

``` go
func ReadFull(r Reader, buf []byte) (n int, err error)
```

Эта функция проверяет, что буфер полностью заполнен перед тем, как вернуть значение. Если размер полученных данных отличается от размера буфера, то вы получите ошибку `io.ErrUnexpectedEOF`. Эта простая гарантия упрощает код довольно сильно. Чтобы прочесть 8 байт, достаточно сделать так:


``` go
buf := make([]byte, 8)
if _, err := io.ReadFull(r, buf); err != nil {
    return err
}
```

Ещё одна чуть реже используемая вспомогательная функция это `ReadAtLeast()`:

``` go
func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error)
```

Эта функция записывает доступные для чтения данные в ваш буфер, но не менее указанного количества байт. 


<!-- легко могу представить её пользу для случаев, когда вы хотите уменьшить количество вызовов Read() и буферизировать дополнительные данные. -->


### Объединение потоков

Нередко вы можете встретить ситуацию, где вам необходимо объединить несколько ридеров вместе. Это легко сделать с помощью `MultiReader`:

``` go
func MultiReader(readers ...Reader) Reader
```

Например, вы хотите отправить HTTP ответ, в котором заголовок читается из памяти, а содержимое тела ответа — из файла. Многие люди сначала прочитают файл в буфер в памяти перед отправкой, но это медленно и может требовать много памяти.


Вот более простой подход:

``` go
r := io.MultiReader(
    bytes.NewReader([]byte("...my header...")),
    myFile,
)
http.Post("http://example.com", "application/octet-stream", r)
```

`MultiReader` даёт возможность `http.Post()` использовать оба ридера как один.

### Ограничение длины потока

Поскольку потоки никак не ограничены по размеру, иногда чтение из них может привести к проблемам с памятью или местом на диске. Типичный пример это хендлер, осуществляющий загрузку файла. Обычно существуют лимиты на максимальный размер загружаемого файла, чтобы не переполнять диск, но может быть утомительно имплементировать их вручную.


`LimitReader` даёт нам эту функциональность, предоставляя обёртку вокруг ридера, который ограничивает количество байт, доступных для вычитки.


``` go
func LimitReader(r Reader, n int64) Reader
```

Один из моментов при работе с `LimitReader`-ом это то, что он не скажет вам, если `r` вычитал больше, чем n. Он просто вернёт `io.EOF`, как только вычитает n байт. Как вариант, можно выставить лимит в n+1 и потом проверить, прочитали ли вы больше, чем n байт в конце.

## Запись данных 

### Интерфейс Writer
`io.Writer`

``` go
Copy
type Writer interface {
  Write(p []byte) (n int, err error)
}
```
**Примеры**: файлы, буферы, HTTP-ответы.

<!-- В общем случае, запись байтов это более простая операция, чем чтение. С ридерами сложность в том, чтобы правильно работать с частичными и не полными чтениями, но при частичной или неполной записи, мы просто получаем ошибку. -->

#### Пример записи в буфер
``` go 
var buf bytes.Buffer
buf.Write([]byte("Hello")) // запись байтов
fmt.Fprintf(&buf, ", %s!", "Go") // форматированный вывод
```
#### Пример записи в файл
``` go
// Создаем файл (если существует, перезаписываем)
file, err := os.Create("output.txt")
if err != nil {
    panic(err)
}
defer file.Close() // Закрываем файл в конце

// Записываем строку
bytesWritten, err := file.WriteString("Hello, File!\n")
if err != nil {
    panic(err)
}
fmt.Printf("Записано %d байт.\n", bytesWritten)

// Записываем байты
data := []byte{72, 101, 108, 108, 111, 33} // "Hello!" в ASCII
bytesWritten, err = file.Write(data)
if err != nil {
    panic(err)
}
fmt.Printf("Записано %d байт.\n", bytesWritten)

// Используем fmt.Fprintf для форматированной записи
fmt.Fprintf(file, "Сегодня: %s\n", "2023-10-05")
```
#### Пример записи в сеть (TCP-сервер)
``` go 
ln, err := net.Listen("tcp", ":8080")
if err != nil {
    panic(err)
}
defer ln.Close()

for {
    conn, err := ln.Accept()
    if err != nil {
        continue
    }

    go func(c net.Conn) {
        defer c.Close()
        c.Write([]byte("Время сервера: " + time.Now().String() + "\n"))
    }(conn)
}
```

### Дублирование записи
Иногда вам нужно отправить данные сразу в несколько `writer`-ов. 

<!-- Например, в лог файл и в `STDERR`. Это похоже на `TeeReader`, только мы хотим дублировать запись, а не чтение. -->


В этом случае нам подойдёт `MultiWriter`:

``` go
func MultiWriter(writers ...Writer) Writer
```

Имя может немного сбивать толку, потому что это не совсем `writer`-версия `MultiReader`. Если `MultiReader` объединяет несколько ридеров в один, то `MultiWriter` возвращает writer, который дублирует записи во все `writer`-ы.


`MultiWriter` можно использовать, например, в `unit`-тестах, чтобы убедиться, что сервисы пишут в лог корректно:


``` go
type MyService struct {
        LogOuput io.Writer
}
...
var buf bytes.Buffer
var s MyService
s.LogOutput = io.MultiWriter(&buf, os.Stderr)
``` 

Использование `MultiWriter` позволяет проверить содержимое buf и при этом видеть полный вывод логов в терминале для отладки.

## Комбинации Reader и Writer 

### TeeReader 
<!-- Один из моментов, которые вам могут встретиться при работе с ридерами это то, что если данные были вычитаны, их нельзя прочитать ещё раз. Например, ваше приложение не смогло распарсить тело HTTP запроса, но вы не можете его проанализировать, потому что парсер уже прочёл данные, их больше нет в ридере. -->

`TeeReader` позволяет сохранять вычитанные данные, при этом не мешая процессу чтения.

``` go
func TeeReader(r Reader, w Writer) Reader
```

<!-- Эта функция создаёт новый ридер-обёртку вокруг вашего ридера r. Любая операция чтения из нового ридера будет также записывать данные в w. Этот `writer` может представлять собой всё что угодно — от буфера в памяти, до лог файла и до потока стандартных ошибок `STDERR`. -->


Например, вы можете захватывать ошибочные запросы следующим образом:


``` go
var buf bytes.Buffer
body := io.TeeReader(req.Body, &buf)

// ... process body ...

if err != nil {
        // inspect buf
        return err
}
```

Впрочем, тут важно быть внимательными с размерами вычитанного тела ответа, чтобы не израсходовать память.

### Копирование 
Самый простой способ скопировать из `reader` во `writer` это использовать функцию `Copy()`:


``` go
func Copy(dst Writer, src Reader) (written int64, err error)
``` 

Эта функция использует буфер в 32 КБ, чтобы прочитать из src и записать в dst. Если случится ошибка, отличная от `io.EOF`, копирование остановится и вернётся ошибка.


<!-- Одна из проблем с `Copy()` заключается в том, что у вас нет способа гарантировать максимальное количество скопированных байт. Например, вы хотите скопировать лог файл до его текущего размера. Если же лог продолжит расти во время копирования, вы получите больше байт, чем ожидалось. В этом случае можно использовать функцию `CopyN()`, которая скопирует не больше указанного количества: -->

`CopyN`

``` go
func CopyN(dst Writer, src Reader, n int64) (written int64, err error)
``` 

<!-- Ещё один важный момент с Copy() заключается в том, что при каждом копировании выделяется буфер в 32КБ. Если вам нужно делать много операций копирования, вы можете переиспользовать уже выделенный буфер и использовать CopyBuffer(): -->

`CopyCopyBuffer`

``` go
func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error)
``` 

### Адаптация ридеров и райтеров

Иногда вы оказываетесь в ситуации, когда у вас есть функция, принимающая `Reader`, но у вас есть только `Writer`. Возможно, вы хотите динамически записать данные в HTTP запрос, но `http.NewRequest()` принимает только `Reader`.


Вы можете инвертировать райтер, используя `io.Pipe()`:

``` go
func Pipe() (*PipeReader, *PipeWriter)
```

Тут вы получаете новый reader и writer. Любая запись в `PipeWriter` переправится в `PipeReader`.


`exec.Cmd` использует её для реализации `Stdin`, `Stdout` и `Stderr` пайпов, которые могут быть очень полезны при работе c запускаемыми программами.




## Закрытие потоков

Интерфейс `Closer` предоставляет общий способ закрывать потоки:

``` go 
type Closer interface {
        Close() error
}
```

<!-- Тут особо не о чем писать, интерфейс этот очень простой, но я стараюсь всегда возвращать ошибку в моих `Close()` методах, чтобы мои типы реализовывали этот интерфейс, если потребуется. `Closer` не всегда используется напрямую, он чаще идёт в сочетании с другими интерфейсами, такими как `ReadCloser`, `WriteCloser` и `ReadWriteCloser`. -->


## Навигация по потокам

Потоки обычно представляют собой постоянно появляющиеся данные от начала до конца, но бывают исключения. Файл, к примеру, может быть потоком, но при этом вы также можете произвольно перемещаться к любой позиции внутри файла.


Интерфейс `Seeker` предоставляет возможность перемещаться внутри потока:

``` go
type Seeker interface {
        Seek(offset int64, whence int) (int64, error)
}
```

Есть три способа прыгать на нужную позицию: переход от текущей позиции, переход с начала потока и переход с конца. Вы указываете этот способ аргументом whence. Аргумент offset указывает на сколько байт переместиться.


<!-- Перемещение по потоку может быть полезным, если вы используете блоки фиксированного размера или если ваш файл содержит индекс со смещениями. Иногда данные находятся в заголовке и логично использовать переход с начала потока, но иногда данные находятся в хвосте и удобнее перемещаться с конца. -->

## Специальные интерфейсы 

<!-- Чтение и запись порциями могут быть утомительны, если всё что вам нужно это один байт или руна (rune). В Go для этого есть интерфейсы, которые облегчают жизнь. -->


### Работа с индивидуальными байтами

Интерфейсы `ByteReader` и `ByteWriter` предоставляют простые методы для чтения и записи одного байта:


``` go
type ByteReader interface {
        ReadByte() (c byte, err error)
}
type ByteWriter interface {
        WriteByte(c byte) error
}
```

<!-- Заметьте, что тут нет параметра для количества байт, это всегда будет 0 или 1. Если байт не был прочитан или записан, возвращается ошибка. -->


Также есть `ByteScanner` интерфейс:
<!-- позволяющий удобно работать с буферизированными ридерами для байт -->

```go
type ByteScanner interface {
    ByteReader
    UnreadByte() error
}
```

Этот интерфейс позволяет вернуть байт обратно в поток. 

<!-- Это бывает удобно, например при написании LL(1) парсеров, так как позволяет заглядывать на байт вперёд. -->


### Работа с индивидуальными рунами

Если вы парсите Unicode данные, то вы должны работать с рунами вместо индивидуальных байт. В этом случае вы должны использовать интерфейсы `RuneReader` и `RuneScanner`:


```go
type RuneReader interface {
        ReadRune() (r rune, size int, err error)
}
type RuneScanner interface {
        RuneReader
        UnreadRune() error
}
```

